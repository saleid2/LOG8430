STEP 1: DEPENDENCIES
1. In order to run the server, you must have Python 2.7 ONLY.
The following requirements are needed, and can be installed through PIP:
 - Flask (latest version)
 - requests (latest version)
 - pyspark (2.3.2) (pip install pyspark==2.3.2)
 - numpy (latest version)
 - pymongo (latest version)
 
 2. Additional requirement:
 Install a local MongoDB server for testing purposes.

 3. Enter MongoDB information in server_config.py
 
 4. This app is compatible with Spark 2.3.x, not with Spark 2.4.x.
 Install Apache Spark on Ubuntu using this tutorial : https://medium.com/devilsadvocatediwakar/installing-apache-spark-on-ubuntu-8796bfdd0861
 
 STEP 2: RUN THE SERVER ITSELF
 1. When serv.py is running (that means Spark is too!):
  (If you followed the tutorial above correctly $SPARKHOME links to /usr/local/spark)
 2. We need to launch TWO local slaves:
 2.1 To do so, copy the file spark-env.sh into "/usr/local/spark/conf"
 2.2 Use the following command to launch a slave: 
		sudo $SPARK_HOME/sbin/start-slave.sh <spark-master-URL>
	 In this case, spark-master-URL is: spark://localhost:7077
		sudo $SPARK_HOME/sbin/start-slave.sh spark://localhost:7077

